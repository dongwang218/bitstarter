{"cells":[{"cell_type":"code","source":["%sql show databases"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Reference pyspark.sql.Row object\nfrom pyspark.sql import Row\n\n# Build the array of Row objects\narray = [Row(key=\"a\", group=\"vowels\", value=1),\n         Row(key=\"b\", group=\"consonants\", value=2),\n         Row(key=\"c\", group=\"consonants\", value=3),\n         Row(key=\"d\", group=\"consonants\", value=4),\n         Row(key=\"e\", group=\"vowels\", value=5)]\n\n# Create RDD using sc.parallelize and then transforms it into a DataFrame\ndf = sqlContext.createDataFrame(sc.parallelize(array))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df.registerTempTable(\"ScalaTempTable\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql select * from ScalaTempTable"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"small_sql_test_python","notebookId":506239},"nbformat":4,"nbformat_minor":0}
